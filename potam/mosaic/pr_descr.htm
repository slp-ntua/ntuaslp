<?xml version="1.0" encoding="iso-8859-7"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Pattern Recognition Course</title>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-7" />
</head>
<body>

<h3>
Στατιστική Μοντελοποίηση και Αναγνώριση Προτύπων 
</h3>

<p>
Το μάθημα εισάγει τον φοιτητή στις έννοιες της θεωρίας απόφασης, της επιλογής 
χαρακτηριστικών μοντελοποίησης, των αλγορίθμων εκτίμησης παραμέτρων μοντέλου και 
των αλγορίθμων αναγνώρισης προτύπων με βάση στατιστικά μοντέλα. Η στατιστική 
μοντελοποίηση και αναγνώριση βρίσκει εφαρμογή στην επεξεργασία φωνής, 
επεξεργασία εικόνας, όραση υπολογιστών, επεξεργασία φυσικής γλώσσας, 
τεχνητή νοημοσύνη και σε πολλές περιοχές των Τηλεπικοινωνιών και της Πληροφορικής.
</p>

<p>
Το μάθημα καλύπτει σε βάθος τις παρακάτω έννοιες: 
Εισαγωγή στη στατιστική. Θεωρία απόφασης Bayes, 
μέθοδοι εκμάθησης με μεγιστοποίηση πιθανότητας (maximum likelihood), 
εκτίμηση πιθανότητας με την μέθοδο Bayes, expectation maximization 
algorithm, κρυφά μοντέλα Markov. Γραμμικοί Ταξινομητές.
Επιλογή χαρακτηριστικών μοντελοποίησης. 
Εκμάθηση χωρίς επίβλεψη, αλγόριθμος απόφασης κοντινότερου γείτονα, 
k-means clustering.  
</p>

<p>
¶λλες έννοιες που θα συζητηθούν στο μάθημα: 
Μη γραμμικοί ταξινομητές, αλγόριθμος perceptron, πολυστρωματικά νευρωνικά δίκτυα.
Μη μετρικές μέθοδοι ταξινόμησης, δέντρα ταξινόμησης και αναδρομής  
(classification and regression trees).  
Μετασχηματισμοί χαρακτηριστικών, ανάλυση πρωτευόντων συνιστωσών (PCA).
μοντέλα γράφων (Bayesian networks), simulated annealing, Markov random fields, 
γεννητικοί αλγόριθμοι, μη παραμετρικές μέθοδοι (Parzen windows), 
support vector machines, boosting.
</p>




<h3>
Statistical Modeling and Pattern Recognition
</h3>



<p>
The "Statistical Modeling and Pattern Recognition" course 
is a hands-on introduction to Bayesian Decision Theory, Parameter
Estimation, Feature Selection and Classification. The course requires a solid 
foundation in probability theory, random processes and a basic understanding 
of statistics.  The course covers in depth material that will be
used in courses like Speech Processing, Natural Language Processing, 
Image Processing, Computer Vision, Artificial Intelligence and other advanced 
courses in Signal Processing, Communications and Computer Science.  
</p>

<p>
The concepts and algorithms that will be covered in depth include: 
Introduction to Statistics, Bayesian Decision Theory, 
Maximum Likelihood and Bayesian Parameter Estimation, 
Expectation Maximization, Hidden Markov Models;
Linear Classifiers and Discriminant Functions, Least Squares Methods; 
Feature Selection; Unsupervised Training and Clustering (k-means, nearest neighbor etc.).
</p>

<p>
The course will also touch on more advanced concepts such as:
Non-linear Classifiers, Multilayer Perceptrons and Neural Networks; 
Graphical models (Bayesian networks); Stochastic learning,  
Non-Metric Methods, Classification and Regression Trees; 
Feature Generation and Feature Transformations (PCA, KL transform); 
Simulated Annealing, Markov Random Fields, Genetic Algorithms; 
Non-parametric methods, Parzen windows; Support Vector Machines; Boosting.
</p>


</body>
</html>
